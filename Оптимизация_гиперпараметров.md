# Оптимизация гиперпараметров
## GridSearchCV (поиск по сетке)

Подбор по сетке параметров:

```python

from sklearn.model_selection import GridSearchCV

# Подбор гиперпараметров для RandomForest

grid_space={'max_depth':[3,5,10,None],
              'n_estimators':[10,100,200],
              'max_features':[1,3,5,7],
              'min_samples_leaf':[1,2,3],
              'min_samples_split':[1,2,3]
           }

grid = GridSearchCV(rf,param_grid=grid_space,cv=3,scoring='accuracy')

model_grid = grid.fit(X,y)

# Оценка результатов
# Выведем самую высокую степень точности модели и набор гиперпараметров, которые обеспечили такой результат

print('Best hyperparameters are: '+str(model_grid.best_params_))
print('Best score is: '+str(model_grid.best_score_))
```

## RandomizedSearchCV (случайный поиск)

определим диапазон значений гиперпараметров для реализации случайного поиска. Эта область параметров может иметь больший диапазон значений, чем та, которая использовалась в поиске по сетке, поскольку случайный поиск не пытается полностью опробовать все комбинации гиперпараметров.

Он случайным образом выбирает гиперпараметры, чтобы найти лучшие из них, и это означает, что в отличие от сеточного поиска, случайный поиск может быстро перебрать большое количество значений.

```python
from scipy.stats import randint

rs_space={'max_depth':list(np.arange(10, 100, step=10)) + [None],
              'n_estimators':np.arange(10, 500, step=50),
              'max_features':randint(1,7),
              'criterion':['gini','entropy'],
              'min_samples_leaf':randint(1,4),
              'min_samples_split':np.arange(2, 10, step=2)
         }
         
from sklearn.model_selection import RandomizedSearchCV

rf = RandomForestClassifier()

# n_iter=500 значит случайный поиск будет выполняться 500 раз, прежде чем будет выбрана лучшая модель

rf_random = RandomizedSearchCV(rf, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=3)

model_random = rf_random.fit(X,y)

# Оценка результатов
# Выведем самую высокую степень точности модели и набор гиперпараметров, которые обеспечили такой результат

print('Best hyperparameters are: '+str(model_random.best_params_))
print('Best score is: '+str(model_random.best_score_))
```
## Экспериментальные оптимизаторы гиперпараметров: model_selection.HalvingGrid и HalvingRandomSearchCV

Появились в версии 0.24 Sklearn.

[model_selection.HalvingGrid](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html)

[HalvingRandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html?highlight=halvingrandomsearchcv#sklearn.model_selection.HalvingRandomSearchCV)

В отличие от своих комплексных родственников GridSearch и RandomizedSearch, новые классы используют технику под названием Successive Halving. Вместо того чтобы обучать все наборы претендентов на всех данных, параметры задаются только на подмножестве данных. Худшие кандидаты отфильтровываются путем их обучения на меньшем подмножестве данных. После каждой итерации число обучающих образцов увеличивается на некоторый коэффициент, а количество возможных претендентов уменьшается на столько же, что приводит к значительному ускорению времени оценки.

По результатам проведенных экспериментов HalvingGridSearch оказался в 11 раз быстрее обычного GridSearch, а HalvingRandomSearch работал в 10 раз быстрее HalvingGridSearch.

## Советы по использованию

1. Используйте поиск по сетке, если у вас уже есть примерный диапазон известных значений гиперпараметров, которые будут работать хорошо. Убедитесь, что область значений параметров невелика, так как поиск по сетке может занять очень много времени. 

2. Применяйте случайный поиск в широком диапазоне значений, если у вас еще нет представления о параметрах, которые будут хорошо работать в вашей модели. Случайный поиск быстрее, чем поиск по сетке, и его всегда следует использовать, когда у вас большая область значений параметров.

3. Для получения наилучших результатов целесообразно использовать как случайный поиск, так и поиск по сетке.

4. При больших размерах области значений параметров можно сначала использовать случайный поиск, так как он быстрее. Затем, используя лучшие гиперпараметры, найденные при случайном поиске, сузить сетку параметров и ввести в сеточный поиск меньший диапазон значений.

## Фреймворк Optuna

[Статья на Хабре](https://habr.com/ru/post/704432/)

## ProgressiveGridSearch
[Habr.com: Пора забывать GridSearch — встречайте ProgressiveGridSearch. Фракталы в ML, постепенно увеличиваем разрешение](https://habr.com/ru/post/726222/)
